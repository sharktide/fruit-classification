{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GPF_BjYa4be",
        "outputId": "e47086a2-0b56-4e7f-d1ee-4b65bc25df46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /kaggle/input/fruits\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"moltean/fruits\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tW2kV9RaBJM",
        "outputId": "281b826c-d402-463e-99c1-e723a3585176"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Set mixed precision policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# Initialize custom ResNet block utilities\n",
        "kaiming_normal = tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
        "\n",
        "def conv3x3(x, out_planes, stride=1, name=None):\n",
        "    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n",
        "    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n",
        "\n",
        "def basic_block(x, planes, stride=1, downsample=None, name=None):\n",
        "    identity = x\n",
        "\n",
        "    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n",
        "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n",
        "    out = layers.ReLU(name=f'{name}.relu1')(out)\n",
        "\n",
        "    out = conv3x3(out, planes, name=f'{name}.conv2')\n",
        "    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n",
        "\n",
        "    if downsample is not None:\n",
        "        for layer in downsample:\n",
        "            identity = layer(identity)\n",
        "\n",
        "    out = layers.Add(name=f'{name}.add')([identity, out])\n",
        "    out = layers.ReLU(name=f'{name}.relu2')(out)\n",
        "    return out\n",
        "\n",
        "def make_layer(x, planes, blocks, stride=1, name=None):\n",
        "    downsample = None\n",
        "    inplanes = x.shape[3]\n",
        "    if stride != 1 or inplanes != planes:\n",
        "        downsample = [\n",
        "            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n",
        "            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n",
        "        ]\n",
        "\n",
        "    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n",
        "    for i in range(1, blocks):\n",
        "        x = basic_block(x, planes, name=f'{name}.{i}')\n",
        "    return x\n",
        "\n",
        "def resnet(x, blocks_per_layer):\n",
        "    x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n",
        "    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n",
        "    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n",
        "    x = layers.ReLU(name='relu1')(x)\n",
        "    x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n",
        "    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n",
        "\n",
        "    x = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n",
        "    x = make_layer(x, 128, blocks_per_layer[1], stride=2, name='layer2')\n",
        "    x = make_layer(x, 256, blocks_per_layer[2], stride=2, name='layer3')\n",
        "    x = make_layer(x, 512, blocks_per_layer[3], stride=2, name='layer4')\n",
        "\n",
        "    # Remove the final Dense layer (fc)\n",
        "    return x\n",
        "\n",
        "def resnet18(x):\n",
        "    return resnet(x, [2, 2, 2, 2])\n",
        "\n",
        "# Define paths and parameters\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 32\n",
        "num_classes = 60\n",
        "\n",
        "str_path = '/kaggle/input/fruits/fruits-360_original-size/fruits-360-original-size/Training'\n",
        "data_dir_train = pathlib.Path(str_path)\n",
        "\n",
        "str_path = '/kaggle/input/fruits/fruits-360_original-size/fruits-360-original-size/Test'\n",
        "data_dir_val = pathlib.Path(str_path)\n",
        "\n",
        "# data_dir_train = pathlib.Path('/root/.cache/kagglehub/datasets/moltean/fruits/versions/32/fruits-360-original-size/Training')\n",
        "# data_dir_val = pathlib.Path('/root/.cache/kagglehub/datasets/moltean/fruits/versions/32/fruits-360-original-size/Test')\n",
        "\n",
        "# Load datasets\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir_val,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "])\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "# Apply caching and prefetching\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Build ResNet18 model\n",
        "inputs = Input(shape=(img_height, img_width, 3))\n",
        "base_model = resnet18(inputs)  # Now outputs feature maps (4D tensor)\n",
        "\n",
        "# Add the classification head\n",
        "x = layers.GlobalAveragePooling2D()(base_model)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "callbacksUsed = [\n",
        "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss'),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=50,\n",
        "    callbacks=callbacksUsed\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('fruit_detection.keras')\n",
        "print(\"Training with ResNet18 completed and model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGolIbDhc3cN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
